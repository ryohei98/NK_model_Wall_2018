{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Graduation_Paper_final_ver.ipynb ",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ryohei98/NK_model_Wall_2018/blob/main/Graduation_Paper_final_ver.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mITRU4R0ndVb"
      },
      "source": [
        "#Driveをマウントする"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itXvbOmRnoI-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f2b0c60-7476-4f92-f17c-ad1845e89386"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrM6vpP6npTe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f971f11e-f2b2-4e1b-e25e-4e68dc75b78b"
      },
      "source": [
        "!ls drive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6h3tnVymYi-O"
      },
      "source": [
        "##適応度地形の生成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AO7OEqTqViio"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "'''\n",
        "Created on Wed Jun 13 15:42:13 2018\n",
        "Updated on Tue May 21 08:49:00 2019\n",
        "@author: Maciej Workiewicz\n",
        "The code has been tested on Python 2.7 and 3.6 and higher\n",
        "'''\n",
        "\n",
        "print('''\n",
        "----------------------------------------------------\n",
        "Running Module 1: NK landscape creation and analysis\n",
        "----------------------------------------------------\n",
        "''')\n",
        "\n",
        "# COMMENTS\n",
        "\n",
        "# =============================================================================\n",
        "# This code generates NK landscapes for a specific interaction matrix (IM) and \n",
        "# number of interactions between the decision variables (K). It has been created\n",
        "# for NK landscapes with N=6, but it can be adapted to for other values of N.\n",
        "# You can choose the type of an interaction matrix by setting variable\n",
        "# 'which_imatrix' to:\n",
        "#     1 - for a random interaction matrix (IM)\n",
        "#     2 - for a modular (block-diagonal) IM\n",
        "#     3 - for a nearly modular IM\n",
        "#     4 - for a diagonal IM\n",
        "#     5 - highly influential IM (Baumann & Siggelkow 2013)\n",
        "#     6 - highly dependent IM (Baumann & Siggelkow 2013)\n",
        "#     7 - Local IM (Rivkin and Siggelkow, 2007)\n",
        "# \n",
        "# For the random IM the user can also set K from 0 to N-1 to tune the number of\n",
        "# interactions.\n",
        "# =============================================================================\n",
        "\n",
        "\n",
        "# *** IMPORTED PACKAGES ***\n",
        "import numpy as np\n",
        "import itertools\n",
        "import os # new\n",
        "from time import time\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "\n",
        "start = time()  # starts the clock used to measure the execution speed\n",
        "\n",
        "# *** MODEL INPUTS ****************************************************\n",
        "\n",
        "# NK landscape parameters -----------------------------------------\n",
        "N = 6  # number of detailed decisions per lower level landscape   |\n",
        "i = 1000  # we will generate 1000 NK landscapes to begin with     |\n",
        "# -----------------------------------------------------------------\n",
        "\n",
        "# You can change the following variables:\n",
        "which_imatrix = 1  # defines the type of an interaction matrix\n",
        "                   # choose 1 for random, 2 for modular, 3 for nearly modular,\n",
        "                   # 4 for diagonal, 5 for highly influential, and\n",
        "                   # 6 for highly dependent, 7 local (see below)\n",
        "K = 5  # only has an effect when you choose the random interaction matrix (1)\n",
        "       # set to 2 for other interaction matrices\n",
        "\n",
        "file_specific = '_t_100_ver_' #ファイルにつける特異的な名前\n",
        "\n",
        "\n",
        "# *** GENERATING INTERACTION MATRICES ***************************************\n",
        "\n",
        "def imatrix_rand(D,K):\n",
        "    '''\n",
        "    グループ分け可能\n",
        "    ・部門数＝D\n",
        "    ・グループに含まれる要素数＝P（以下に定義）\n",
        "    '''\n",
        "    P = N/D\n",
        "    #zeros()_縦N個横N個の配列を全要素０の状態で生成\n",
        "    Int_matrix_rand = np.zeros((N, N))\n",
        "\n",
        "    #arrange(start,stop,kousa,dtype)_0~NでPの公差を持つ等差数列を配列の形で生成\n",
        "    for aa1 in np.arange(0,N,P,dtype = int):\n",
        "      Ln = aa1 + P\n",
        "      for aa2 in np.arange(aa1,Ln,1,dtype = int):\n",
        "\n",
        "        #range(N)_0~Nの連番を配列で生成する\n",
        "        Indexes_1 = list(range(N))\n",
        "        for i in np.arange(aa1,Ln,1,dtype = int):\n",
        "\n",
        "          #remove(i)_同じ値を検索し、最初の要素を削除する\n",
        "          Indexes_1.remove(i)  # remove selves\n",
        "\n",
        "        #numpy.random.shuffle()_配列の要素をシャッフルする（in-place)  \n",
        "        np.random.shuffle(Indexes_1)\n",
        "        for i in np.arange(aa1,Ln,1,dtype = int):\n",
        "          #append()_配列に新しい要素を追加する\n",
        "          Indexes_1.append(i)\n",
        "\n",
        "          #[-(K+1):最後]という意味\n",
        "        Chosen_ones = Indexes_1[-(K+1):]  # this takes the last K+1 indexes\n",
        "        for aa3 in Chosen_ones:\n",
        "          Int_matrix_rand[aa2, aa3] = 1  # we turn on the interactions with K other variables\n",
        "    return(Int_matrix_rand)\n",
        "\n",
        "\n",
        "\n",
        "#==============================================================================\n",
        "# Below are the other three types of interaction matrices.\n",
        "# You can edit those if you want to check other petterns of interactions.\n",
        "#==============================================================================\n",
        "\n",
        "if which_imatrix == 2:  # MODULAR\n",
        "    K = 2  # set to the average value\n",
        "    Int_matrix = \\\n",
        "        np.array([\n",
        "                 [1, 1, 1, 0, 0, 0],\n",
        "                 [1, 1, 1, 0, 0, 0],\n",
        "                 [1, 1, 1, 0, 0, 0],\n",
        "                 [0, 0, 0, 1, 1, 1],\n",
        "                 [0, 0, 0, 1, 1, 1],\n",
        "                 [0, 0, 0, 1, 1, 1]\n",
        "                 ])\n",
        "\n",
        "elif which_imatrix == 3:  # NEARLY MODULAR\n",
        "    K = 2  # set to the average value\n",
        "    Int_matrix = \\\n",
        "        np.array([\n",
        "                 [1, 1, 1, 0, 0, 0],\n",
        "                 [1, 1, 1, 0, 0, 0],\n",
        "                 [1, 0, 1, 1, 0, 0],\n",
        "                 [0, 0, 1, 1, 0, 1],\n",
        "                 [0, 0, 0, 1, 1, 1],\n",
        "                 [0, 0, 0, 1, 1, 1]\n",
        "                 ])\n",
        "elif which_imatrix == 4:  # DIAGONAL\n",
        "    K = 2  # set to average value and updated code below to poke three random holes\n",
        "    Int_matrix4 = \\\n",
        "        np.array([\n",
        "                 [1, 0, 0, 0, 0, 0],\n",
        "                 [1, 1, 0, 0, 0, 0],\n",
        "                 [1, 1, 1, 0, 0, 0],\n",
        "                 [1, 1, 1, 1, 0, 0],\n",
        "                 [1, 1, 1, 1, 1, 0],\n",
        "                 [1, 1, 1, 1, 1, 1]\n",
        "                 ])\n",
        "    \n",
        "elif which_imatrix == 5:  # HIGHLY INFLUENTIAL Baumann & Siggelkow 2013\n",
        "    K = 2  # set to the average value\n",
        "    Int_matrix = \\\n",
        "        np.array([\n",
        "                 [1, 1, 1, 0, 0, 0],\n",
        "                 [1, 1, 1, 0, 0, 0],\n",
        "                 [1, 1, 1, 0, 0, 0],\n",
        "                 [1, 1, 0, 1, 0, 0],\n",
        "                 [1, 1, 0, 0, 1, 0],\n",
        "                 [1, 1, 0, 0, 0, 1]\n",
        "                 ])\n",
        "\n",
        "elif which_imatrix == 6:  # HIGHLY DEPENDENT Baumann & Siggelkow 2013\n",
        "    K = 2  # set to the average value\n",
        "    Int_matrix = \\\n",
        "        np.array([\n",
        "                 [1, 1, 1, 1, 1, 1],\n",
        "                 [1, 1, 1, 1, 1, 1],\n",
        "                 [1, 1, 1, 0, 0, 0],\n",
        "                 [0, 0, 0, 1, 0, 0],\n",
        "                 [0, 0, 0, 0, 1, 0],\n",
        "                 [0, 0, 0, 0, 0, 1]\n",
        "                 ])\n",
        "elif which_imatrix == 7:  # LOCAL Rivkin and Siggelkow, 2007\n",
        "    K = 2  # set to the average value\n",
        "    Int_matrix = \\\n",
        "        np.array([\n",
        "                 [1, 1, 0, 0, 0, 1],\n",
        "                 [1, 1, 1, 0, 0, 0],\n",
        "                 [0, 1, 1, 1, 0, 0],\n",
        "                 [0, 0, 1, 1, 1, 0],\n",
        "                 [0, 0, 0, 1, 1, 1],\n",
        "                 [1, 0, 0, 0, 1, 1]\n",
        "                 ])\n",
        "\n",
        "# *** NK GENERATING FUNCTIONS ***********************************************\n",
        "def calc_fit(NK_land_, inter_m, Current_position, Power_key_):\n",
        "    '''\n",
        "    Takes the landscape and a given combination and returns a vector of fitness\n",
        "    values for the vector of the N decision variables.\n",
        "    '''\n",
        "    Fit_vector = np.zeros(N)\n",
        "    for ad1 in np.arange(N):\n",
        "        Fit_vector[ad1] = NK_land_[np.sum(Current_position * inter_m[ad1]\n",
        "                                          * Power_key_), ad1]\n",
        "    return(Fit_vector)\n",
        "\n",
        "\n",
        "def comb_and_values(NK_land_, Power_key_, inter_m):\n",
        "    '''\n",
        "    Calculates values for all combinations on the landscape. The resulting\n",
        "    array contains:\n",
        "    - the first columns indexed from 0 to N-1 are for each of the combinations\n",
        "    - columns indexed from N to 2*N-1 are for the fit value (vector) of those combinations\n",
        "    - the column indexed 2N is for the total fit (average of the entire vector)\n",
        "    - column indexed 2N+1 is a dummy, with 1 indicating a local peak\n",
        "    - the last column is a dummy, with 1 indicating the global peak\n",
        "    '''\n",
        "    Comb_and_value = np.zeros((2**N, N*2+3))  # to capture the results\n",
        "    c1 = 0  # starting counter for location\n",
        "    for c2 in itertools.product(range(2), repeat=N):\n",
        "        # this takes time so be carefull with landscapes of bigger size\n",
        "        Combination1 = np.array(c2)  # taking each combination\n",
        "        fit_1 = calc_fit(NK_land_, inter_m, Combination1, Power_key_)\n",
        "        Comb_and_value[c1, :N] = Combination1  # combination and values\n",
        "        Comb_and_value[c1, N:2*N] = fit_1\n",
        "        Comb_and_value[c1, 2*N] = np.mean(fit_1)\n",
        "        c1 = c1 + 1\n",
        "    for c3 in np.arange(2**N):  # now let's see if it is a local peak\n",
        "        loc_p = 1  # first, assume it is\n",
        "        for c4 in np.arange(N):  # check the local neighbourhood\n",
        "            new_comb = Comb_and_value[c3, :N].copy().astype(int)\n",
        "            new_comb[c4] = abs(new_comb[c4] - 1)\n",
        "            if ((Comb_and_value[c3, 2*N] <\n",
        "                 Comb_and_value[np.sum(new_comb*Power_key_), 2*N])):\n",
        "                loc_p = 0  # if smaller than the neighbour, then it is not peak\n",
        "        Comb_and_value[c3, 2*N+1] = loc_p\n",
        "    max_ind = np.argmax(Comb_and_value[:, 2*N])\n",
        "    Comb_and_value[max_ind, 2*N+2] = 1\n",
        "    return(Comb_and_value)\n",
        "\n",
        "\n",
        "# *** GENERATING THE NK LANDSCAPES ******************************************\n",
        "Power_key = np.power(2, np.arange(N - 1, -1, -1))  # used to find addresses on the landscape\n",
        "Landscape_data = np.zeros((i, 2**N, N*2+3))  # we prepare an array to receive the data\n",
        "\n",
        "for i_1 in np.arange(i):\n",
        "    '''\n",
        "    Now we create the landscapes\n",
        "    '''\n",
        "    if which_imatrix==1:\n",
        "        Int_matrix = imatrix_rand().astype(int)\n",
        "    elif which_imatrix==4:  # diagonal\n",
        "        '''\n",
        "        The code below serves to poke three holes in the diagonal IM so that\n",
        "        K=2. It is a little bit cumbersome but does the job  :-)\n",
        "        Note that it only works with N=6\n",
        "        '''\n",
        "        Int_matrix = Int_matrix4.copy()\n",
        "        id_change = random.sample(range(15), 3)\n",
        "        for index in id_change:\n",
        "            if index == 0:\n",
        "                Int_matrix[1,0] = 0\n",
        "            elif index == 1:\n",
        "                Int_matrix[2,0] = 0\n",
        "            elif index == 2:\n",
        "                Int_matrix[2,1] = 0\n",
        "            elif index == 3:\n",
        "                Int_matrix[3,0] = 0\n",
        "            elif index == 4:\n",
        "                Int_matrix[3,1] = 0\n",
        "            elif index == 5:\n",
        "                Int_matrix[3,2] = 0\n",
        "            elif index == 6:\n",
        "                Int_matrix[4,0] = 0\n",
        "            elif index == 7:\n",
        "                Int_matrix[4,1] = 0\n",
        "            elif index == 8:\n",
        "                Int_matrix[4,2] = 0\n",
        "            elif index == 9:\n",
        "                Int_matrix[4,3] = 0\n",
        "            elif index == 10:\n",
        "                Int_matrix[5,0] = 0\n",
        "            elif index == 11:\n",
        "                Int_matrix[5,1] = 0\n",
        "            elif index == 12:\n",
        "                Int_matrix[5,2] = 0\n",
        "            elif index == 13:\n",
        "                Int_matrix[5,3] = 0\n",
        "            elif index == 14:\n",
        "                Int_matrix[5,4] = 0\n",
        "    \n",
        "    NK_land = np.random.rand(2**N, N)  # this is a table of random U(0,1) numbers\n",
        "    # Now it is time to survey the topography of our NK landscape\n",
        "    Landscape_data[i_1] = comb_and_values(NK_land, Power_key, Int_matrix)\n",
        "\n",
        "\n",
        "# *** CALCULATING SUMMARY STATISTICS ****************************************\n",
        "number_of_peaks = np.zeros(i)\n",
        "max_values = np.zeros(i)\n",
        "min_values = np.zeros(i)\n",
        "\n",
        "for i_2 in np.arange(i):\n",
        "    number_of_peaks[i_2] = np.sum(Landscape_data[i_2, :, 2*N+1])\n",
        "    max_values[i_2] = np.max(Landscape_data[i_2, :, 2*N])\n",
        "    min_values[i_2] = np.min(Landscape_data[i_2, :, 2*N])\n",
        "\n",
        "# Let's print some summary statistics of our sample of NK landscapes\n",
        "print('Summary statistics for IMatrix: ' + str(which_imatrix) + ' K=' + str(K))\n",
        "print('average number of peaks: ' + str(np.mean(number_of_peaks)))\n",
        "print('maximum number of peaks: ' + str(np.max(number_of_peaks)))\n",
        "print('minimum number of peaks: ' + str(np.min(number_of_peaks)))\n",
        "print('average maximum value: ' + str(np.mean(max_values)))\n",
        "print('average minimum value: ' + str(np.mean(min_values)))\n",
        "\n",
        "# plot histogram of the number of local peaks in our sample\n",
        "plt.figure(1, facecolor='white', figsize=(8, 6), dpi=150)  # for screens with\n",
        "#          higher resolution change dpi to 150 or 200. For normal use 75.\n",
        "plt.hist(number_of_peaks, bins=20, range=(1, 20), color='dodgerblue', edgecolor='black') # adjust if necessary\n",
        "plt.title('Distribution of the number of peaks', size=12)\n",
        "plt.xlabel('number of peaks', size=10)\n",
        "plt.ylabel('frequency', size=10)\n",
        "\n",
        "\n",
        "# *** SAVING THE LANDSCAPES AS A BINARY FILE FOR FUTURE RETRIEVAL ************\n",
        "\n",
        "#==============================================================================\n",
        "# If you are saving files on a Mac, change the double back-slash \\\\ into a \n",
        "# single slash /\n",
        "#==============================================================================\n",
        "\n",
        "file_name = os.path.expanduser('~')  # we will save it in your home folder\n",
        "if not os.path.exists(file_name + '\\\\NK_workshop\\\\'):\n",
        "    os.makedirs(file_name + '\\\\NK_workshop\\\\')\n",
        "np.save(file_name + '\\\\NK_workshop\\\\NK_land_type_' + str(which_imatrix) +\n",
        "        '_K_' + str(K) + '_i_' + str(i) + '_' + str(file_specific) + '.npy', Landscape_data)\n",
        "\n",
        "elapsed_time = time() - start\n",
        "print('time: ' + str('%.2f' % elapsed_time) + ' sec')\n",
        "\n",
        "# END OF LINE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cg5gH1xV0iUr"
      },
      "source": [
        "##強化学習を追加してクラス化したモデル"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65aI_ufVmChe"
      },
      "source": [
        "###クラスの読み込み"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sYr28HsmAj2"
      },
      "source": [
        "\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt \r\n",
        "import copy\r\n",
        "\r\n",
        "\r\n",
        "class Var_set:\r\n",
        "  def __init__(self, N, K, Mt, coord, T_star = 20, lamb = 0.5, b = 0.5,sigma_r = 0.1, sigma_head = 0.15):\r\n",
        "    #意思決定の数\r\n",
        "    self.N = int(N)\r\n",
        "    #相互依存レベル\r\n",
        "    self.K = int(K)\r\n",
        "    #組織（Agent)の部門分け\r\n",
        "    self.Mt = int(Mt)\r\n",
        "    #部門外部的相互依存レベル\r\n",
        "    self.Kex = int(self.K - self.get_Nt() +1)\r\n",
        "\r\n",
        "    self.Nt = self.get_Nt()\r\n",
        "    #グループ間の相互関係\r\n",
        "    #0 = decentralized, 1= sequential, 2= proposal\r\n",
        "    self.coord = int(coord)\r\n",
        "\r\n",
        "    self. T_star = T_star\r\n",
        "    self.lamb = lamb\r\n",
        "    self.b = b\r\n",
        "    self.sigma_r = sigma_r\r\n",
        "    self.sigma_head = sigma_head\r\n",
        "\r\n",
        "    #プロパティを名前と中に入っているものを表示\r\n",
        "    for key, value in self.__dict__.items():\r\n",
        "     print(key, ':', value)\r\n",
        "\r\n",
        "  #一部門ごとに割り当てられている意思決定数を返す関数\r\n",
        "  def get_Nt(self):\r\n",
        "    #一部門の意思決定数\r\n",
        "    return int(self.N / self.Mt)\r\n",
        "\r\n",
        "class Environment:\r\n",
        "  def __init__(self, N, landscape):\r\n",
        "    #何枚目の適応度地形を使用するか\r\n",
        "    self.i = 0\r\n",
        "    #意思決定の個数\r\n",
        "    self.N = N\r\n",
        "    #上でつくった適応度地形\r\n",
        "    self.landscape = landscape\r\n",
        "    #2進数→10進数の変換用配列\r\n",
        "    self.converter = np.power(2, np.arange(N-1, -1, -1))\r\n",
        "    #適応度地形ごとの最高点・最低点を入れておく\r\n",
        "    self.reset()\r\n",
        "    #プロパティを名前と中に入っているものを表示\r\n",
        "    # for key, value in self.__dict__.items():\r\n",
        "    #  print(key, ':', value)\r\n",
        "        \r\n",
        "  def reset(self):\r\n",
        "    self.max_fit = np.max(self.landscape[self.i-1, :, 2*self.N])\r\n",
        "    self.min_fit = np.min(self.landscape[self.i-1, :, 2*self.N])\r\n",
        "    # self.max_fit=1\r\n",
        "    # self.min_fit=0\r\n",
        "\r\n",
        "  def step(self):\r\n",
        "    self.i += 1\r\n",
        "    self.reset()\r\n",
        "\r\n",
        "  def get_contr_norm(self, decimal):\r\n",
        "    return (self.landscape[self.i, decimal, 2*self.N] - self.min_fit) / (self.max_fit - self.min_fit)\r\n",
        "\r\n",
        "  def get_norm_from_comb(self, comb):\r\n",
        "    decimal = np.sum(comb * self.converter)\r\n",
        "    norm = self.get_contr_norm(int(decimal))\r\n",
        "    # print('norm:' +str(norm) )\r\n",
        "    return norm\r\n",
        "\r\n",
        "  def get_future_norm_from_comb(self, sigma, comb):\r\n",
        "    norm = self.get_norm_from_comb(comb)\r\n",
        "    norm += np.random.normal(0,sigma)\r\n",
        "    return norm\r\n",
        "\r\n",
        "class Agent:\r\n",
        "  def __init__(self, var_set, environment):\r\n",
        "    self.var_set = var_set\r\n",
        "    self.environment = environment\r\n",
        "    self.comb = np.random.binomial(1, 0.5, var_set.N)\r\n",
        "    self.contr_norm = self.environment.get_norm_from_comb(self.comb)\r\n",
        "    self.rec_norm = [0]\r\n",
        "    self.rec_norm[0] = self.contr_norm \r\n",
        "\r\n",
        "    #プロパティを名前と中に入っているものを表示\r\n",
        "    for key, value in self.__dict__.items():\r\n",
        "     print(key, ':', value)\r\n",
        "\r\n",
        "  def local_search(self):\r\n",
        "    Nt = self.var_set.Nt\r\n",
        "    Mt = self. var_set.Mt\r\n",
        "    sigma_r = self.var_set.sigma_head\r\n",
        "    sigma_head = self.var_set.sigma_head\r\n",
        "\r\n",
        "    if self.var_set.coord == 2: \r\n",
        "      row = 0\r\n",
        "      rec_comb = np.zeros((3, self.var_set.N))\r\n",
        "\r\n",
        "    for a1 in range(Mt):\r\n",
        "      comb_alpha = copy.copy(self.comb)\r\n",
        "      comb_beta = copy.copy(self.comb)\r\n",
        "      comb_current = copy.copy(self.comb)\r\n",
        "      comb_new = copy.copy(self.comb)\r\n",
        "\r\n",
        "      print('self.comb:' + str(self.comb))\r\n",
        "\r\n",
        "      change_key1 = np.random.randint(Nt)\r\n",
        "      change_key2 = np.random.randint(Nt)\r\n",
        "      change_key1 += a1 * Nt\r\n",
        "      change_key2 += a1 * Nt\r\n",
        "      print('change_key1:' + str(change_key1))\r\n",
        "      print('change_key2:' + str(change_key2))\r\n",
        "\r\n",
        "      comb_alpha[change_key1] = abs(comb_alpha[change_key1] -1)\r\n",
        "      comb_beta[change_key2] = abs(comb_alpha[change_key2] -1)\r\n",
        "\r\n",
        "      print('comb_alpha:' + str(comb_alpha))\r\n",
        "      print('comb_beta_:' + str(comb_beta))\r\n",
        "      print('self.comb_:' + str(self.comb))\r\n",
        "\r\n",
        "      contr_alpha = self.environment.get_future_norm_from_comb(sigma_r, comb_alpha)\r\n",
        "      contr_beta = self.environment.get_future_norm_from_comb(sigma_r, comb_beta)\r\n",
        "\r\n",
        "      print('contr_alpha:' + str(contr_alpha))\r\n",
        "      print('contr_beta:' + str(contr_beta))\r\n",
        "      print('self.contr_norm:' + str(self.contr_norm))\r\n",
        "      if self.var_set.coord == 0:\r\n",
        "        if contr_alpha > self.contr_norm and contr_alpha > contr_beta:\r\n",
        "          comb_new[a1*Nt:a1*Nt+Nt] = comb_alpha[a1*Nt:a1*Nt+Nt]\r\n",
        "        elif contr_beta > self.contr_norm and contr_beta > contr_alpha:\r\n",
        "          comb_new[a1*Nt:a1*Nt+Nt] = comb_beta[a1*Nt:a1*Nt+Nt]\r\n",
        "      \r\n",
        "      elif self.var_set.coord == 1:\r\n",
        "        if contr_alpha > self.contr_norm and contr_alpha > contr_beta:\r\n",
        "          self.comb[a1*Nt:a1*Nt+Nt] = comb_alpha[a1*Nt:a1*Nt+Nt]\r\n",
        "        elif contr_beta > self.contr_norm and contr_beta > contr_alpha:\r\n",
        "          self.comb[a1*Nt:a1*Nt+Nt] = comb_beta[a1*Nt:a1*Nt+Nt]\r\n",
        "\r\n",
        "      else:\r\n",
        "        if contr_alpha > self.contr_norm and contr_alpha > contr_beta:\r\n",
        "          rec_comb[0][a1*Nt:a1*Nt+Nt] = comb_alpha[a1*Nt:a1*Nt+Nt]\r\n",
        "          if contr_beta > self.contr_norm:\r\n",
        "            rec_comb[1][a1*Nt:a1*Nt+Nt] = comb_beta[a1*Nt:a1*Nt+Nt]\r\n",
        "            rec_comb[2][a1*Nt:a1*Nt+Nt] = copy.copy(self.comb[a1*Nt:a1*Nt+Nt])\r\n",
        "          else: \r\n",
        "            rec_comb[1][a1*Nt:a1*Nt+Nt] = copy.copy(self.comb[a1*Nt:a1*Nt+Nt])\r\n",
        "            rec_comb[2][a1*Nt:a1*Nt+Nt] = comb_beta[a1*Nt:a1*Nt+Nt]\r\n",
        "\r\n",
        "        elif contr_beta > self.contr_norm and contr_beta > contr_alpha:\r\n",
        "          rec_comb[0][a1*Nt:a1*Nt+Nt] = comb_beta[a1*Nt:a1*Nt+Nt]\r\n",
        "          if contr_alpha > self.contr_norm:\r\n",
        "            rec_comb[1][a1*Nt:a1*Nt+Nt] = comb_alpha[a1*Nt:a1*Nt+Nt]\r\n",
        "            rec_comb[2][a1*Nt:a1*Nt+Nt] = copy.copy(self.comb[a1*Nt:a1*Nt+Nt])\r\n",
        "          else: \r\n",
        "            rec_comb[1][a1*Nt:a1*Nt+Nt] = copy.copy(self.comb[a1*Nt:a1*Nt+Nt])\r\n",
        "            rec_comb[2][a1*Nt:a1*Nt+Nt] = comb_alpha[a1*Nt:a1*Nt+Nt]\r\n",
        "\r\n",
        "        else:\r\n",
        "          rec_comb[0][a1*Nt:a1*Nt+Nt] = copy.copy(self.comb[a1*Nt:a1*Nt+Nt])\r\n",
        "          if contr_alpha > contr_beta:\r\n",
        "            rec_comb[1][a1*Nt:a1*Nt+Nt] = comb_alpha[a1*Nt:a1*Nt+Nt]\r\n",
        "            rec_comb[2][a1*Nt:a1*Nt+Nt] = comb_beta[a1*Nt:a1*Nt+Nt]\r\n",
        "          else: \r\n",
        "            rec_comb[1][a1*Nt:a1*Nt+Nt] =  comb_beta[a1*Nt:a1*Nt+Nt]\r\n",
        "            rec_comb[2][a1*Nt:a1*Nt+Nt] =  comb_alpha[a1*Nt:a1*Nt+Nt]\r\n",
        "    \r\n",
        "      print('----------'+str(a1*Nt))\r\n",
        "      print('rec_comb:'+str(rec_comb))\r\n",
        "\r\n",
        "    if self.var_set.coord == 2:\r\n",
        "      contr_first = self.environment.get_future_norm_from_comb(self.var_set.sigma_head, rec_comb[0])\r\n",
        "      contr_second = self.environment.get_future_norm_from_comb(self.var_set.sigma_head, rec_comb[1])\r\n",
        "      print('contr_first:' + str(contr_first))\r\n",
        "      print('contr_second:' + str(contr_second))\r\n",
        "      print('self.contr_norm:' + str(self.contr_norm))\r\n",
        "\r\n",
        "      if contr_first > contr_second and contr_first > self.contr_norm :\r\n",
        "        comb_new = rec_comb[0]\r\n",
        "      elif contr_second > self.contr_norm:\r\n",
        "        comb_new = rec_comb[1]\r\n",
        "      else:\r\n",
        "        comb_new = self.comb\r\n",
        "    \r\n",
        "    if self.var_set.coord != 1:\r\n",
        "      self.comb = copy.copy(comb_new)\r\n",
        "    \r\n",
        "\r\n",
        "    self.contr_norm = self.environment.get_norm_from_comb(self.comb)\r\n",
        "    self.rec_norm.append(self.contr_norm)\r\n",
        "\r\n",
        "class Manager:\r\n",
        "  def __init__(self,var_set,agent):\r\n",
        "    self.var_set = var_set\r\n",
        "    self.b = self.var_set.b\r\n",
        "    self.lamb = self.var_set.lamb\r\n",
        "    self.T_star = self.var_set.T_star\r\n",
        "    self.A = self.create_A()\r\n",
        "    self.prob_feasibles = self.create_prob_feasibles()\r\n",
        "    self.rec_prob_feasibles = np.zeros((1,len(self.A)))\r\n",
        "    self.rec_prob_feasibles[0] = np.copy(self.prob_feasibles) \r\n",
        "    self.rec_average_norm = np.zeros(1)\r\n",
        "    self.Nu_t = 0\r\n",
        "    self.delta_Vt = 0\r\n",
        "    self.agent = agent\r\n",
        "\r\n",
        "    #プロパティを名前と中に入っているものを表示\r\n",
        "    for key, value in self.__dict__.items():\r\n",
        "     print(key, ':', value)  \r\n",
        "\r\n",
        "  def create_A(self):\r\n",
        "    N = self.var_set.N\r\n",
        "    A = []\r\n",
        "    for m1 in np.arange(N)+1:\r\n",
        "      if N % m1 == 0:\r\n",
        "        A.append(i)\r\n",
        "\r\n",
        "    print(A)\r\n",
        "    return A\r\n",
        "\r\n",
        "  def create_prob_feasibles(self):\r\n",
        "    len_A = len(self.A)\r\n",
        "    prob_feasibles_init = np.zeros(len_A)\r\n",
        "    prob_feasibles_init += 1 / len_A\r\n",
        "    prob_feasibles = np.array(prob_feasibles_init)\r\n",
        "    return prob_feasibles\r\n",
        "\r\n",
        "  def select_Mt(self):\r\n",
        "    if len(self.agent.rec_norm) > self.T_star:\r\n",
        "      self.train()\r\n",
        "    self.var_set.Mt = np.random.choice(self.A, p = self.prob_feasibles)\r\n",
        "\r\n",
        "  def train(self):\r\n",
        "    pre_start_index = len(self.agent.rec_norm)- self.T_star*2 -1\r\n",
        "    this_start_index = pre_start_index + self.T_star\r\n",
        "    pre_performance = np.sum(self.agent.rec_norm[pre_start_index:this_start_index]) / self.T_star \r\n",
        "    this_performance = np.sum(self.agent.rec_norm[this_start_index:] / self.T_star)\r\n",
        "    delta_Vt = (this_performance - pre_performance) / pre_performance\r\n",
        "\r\n",
        "    self.Nu_t = self.b * self.delta_Vt + (1-self.b)*self.Nu_t\r\n",
        "\r\n",
        "    if self.Nu_t > delta_Vt:\r\n",
        "      tau_t = False\r\n",
        "    else :\r\n",
        "      tau_t = True\r\n",
        "\r\n",
        "    prob_feasibles = np.copy(self.prob_feasibles)\r\n",
        "    new_probs = [0]*len(self.A)\r\n",
        "\r\n",
        "    for a in range(len(self.A)):\r\n",
        "      if self.A[a] == Mt:\r\n",
        "        if tau_t:\r\n",
        "          new_probs[a] = prob_feasibles[a] + self.lamb *(1-prob_feasibles[a])\r\n",
        "        else:\r\n",
        "          new_probs[a] = prob_feasibles[a] - self.lamb * prob_feasibles[a]\r\n",
        "      else:\r\n",
        "        if tau_t:\r\n",
        "          new_probs[a] = prob_feasibles[a] - self.lamb * prob_feasibles[a]\r\n",
        "        else:\r\n",
        "          Mt_index = self.A.index(Mt)\r\n",
        "          new_probs[a] = prob_feasibles[a] - self.lamb * ((prob_feasibles[a]*prob_feasibles[Mt_index])/(1-prob_feasibles[Mt_index]))\r\n",
        "      \r\n",
        "      if new_probs[a] < 0.001:\r\n",
        "        new_probs[a] = 0.001\r\n",
        "    \r\n",
        "    new_probs = new_probs / np.sum(new_probs)\r\n",
        "    self.prob_feasibles = new_probs\r\n",
        "    self.rec_prob_feasibles.append(new_probs)    \r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YAL7sc6i-kkO",
        "outputId": "b7e0d1f5-0fc8-4ac8-a53e-e10971597ff9"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "file_specific = '_t_100_ver_' #ファイルにつける特異的な名前\r\n",
        "file_name ='/content/drive/My Drive'\r\n",
        "N = 12  #要素数\r\n",
        "K = 3\r\n",
        "G = 3\r\n",
        "Mt = 3\r\n",
        "i = 1000  # 期数\r\n",
        "t = 500  #一期あたりの回数\r\n",
        "coord = 2\r\n",
        "\r\n",
        "NK_landscape = np.load(file_name + '/NK_workshop/NK_land_type_1' + '_D_' + str(G) + '_K_' + str(K) + '_i_' + str(i) + '.npy')\r\n",
        "var_set = Var_set(N, K, Mt, coord) \r\n",
        "environment = Environment(12, NK_landscape)\r\n",
        "agent = Agent(var_set, environment)\r\n",
        "manager = Manager(var_set, agent)\r\n",
        "for t1 in range(t):\r\n",
        "  agent.local_search()\r\n",
        "  if t1 % var_set.T_star == 0:\r\n",
        "    manager.select_Mt()\r\n",
        "print('rec_norm:' + str(agent.rec_norm))\r\n",
        "plt.plot(agent.rec_norm)\r\n",
        "  \r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "N : 12\n",
            "K : 3\n",
            "Mt : 3\n",
            "Kex : 0\n",
            "Nt : 4\n",
            "coord : 2\n",
            "T_star : 20\n",
            "lamb : 0.5\n",
            "b : 0.5\n",
            "sigma_r : 0.1\n",
            "sigma_head : 0.15\n",
            "var_set : <__main__.Var_set object at 0x7fd967f4ea90>\n",
            "environment : <__main__.Environment object at 0x7fd967f58fd0>\n",
            "comb : [0 1 1 1 0 0 0 1 1 1 1 1]\n",
            "contr_norm : 0.5507453606158919\n",
            "rec_norm : [0.5507453606158919]\n",
            "[1000, 1000, 1000, 1000, 1000, 1000]\n",
            "var_set : <__main__.Var_set object at 0x7fd967f4ea90>\n",
            "b : 0.5\n",
            "lamb : 0.5\n",
            "T_star : 20\n",
            "A : [1000, 1000, 1000, 1000, 1000, 1000]\n",
            "prob_feasibles : [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
            "rec_prob_feasibles : [[0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]]\n",
            "rec_average_norm : [0.]\n",
            "Nu_t : 0\n",
            "delta_Vt : 0\n",
            "agent : <__main__.Agent object at 0x7fd967f09eb8>\n",
            "self.comb:[0 1 1 1 0 0 0 1 1 1 1 1]\n",
            "change_key1:1\n",
            "change_key2:0\n",
            "comb_alpha:[0 0 1 1 0 0 0 1 1 1 1 1]\n",
            "comb_beta_:[1 1 1 1 0 0 0 1 1 1 1 1]\n",
            "self.comb_:[0 1 1 1 0 0 0 1 1 1 1 1]\n",
            "contr_alpha:0.34548400431578363\n",
            "contr_beta:0.42873832090755515\n",
            "self.contr_norm:0.5507453606158919\n",
            "----------0\n",
            "rec_comb:[[0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "self.comb:[0 1 1 1 0 0 0 1 1 1 1 1]\n",
            "change_key1:4\n",
            "change_key2:7\n",
            "comb_alpha:[0 1 1 1 1 0 0 1 1 1 1 1]\n",
            "comb_beta_:[0 1 1 1 0 0 0 0 1 1 1 1]\n",
            "self.comb_:[0 1 1 1 0 0 0 1 1 1 1 1]\n",
            "contr_alpha:0.606522625447814\n",
            "contr_beta:0.6349258856923142\n",
            "self.contr_norm:0.5507453606158919\n",
            "----------4\n",
            "rec_comb:[[0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
            "self.comb:[0 1 1 1 0 0 0 1 1 1 1 1]\n",
            "change_key1:9\n",
            "change_key2:11\n",
            "comb_alpha:[0 1 1 1 0 0 0 1 1 0 1 1]\n",
            "comb_beta_:[0 1 1 1 0 0 0 1 1 1 1 0]\n",
            "self.comb_:[0 1 1 1 0 0 0 1 1 1 1 1]\n",
            "contr_alpha:0.9210989796498321\n",
            "contr_beta:0.8345642948774316\n",
            "self.contr_norm:0.5507453606158919\n",
            "----------8\n",
            "rec_comb:[[0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0.]\n",
            " [0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1.]]\n",
            "contr_first:0.5880972559329414\n",
            "contr_second:0.5129891534372493\n",
            "self.contr_norm:0.5507453606158919\n",
            "self.comb:[0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1.]\n",
            "change_key1:1\n",
            "change_key2:2\n",
            "comb_alpha:[0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1.]\n",
            "comb_beta_:[0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1.]\n",
            "self.comb_:[0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1.]\n",
            "contr_alpha:0.4271426145450433\n",
            "contr_beta:0.5004501814539137\n",
            "self.contr_norm:0.5346931596635712\n",
            "----------0\n",
            "rec_comb:[[0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "self.comb:[0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1.]\n",
            "change_key1:7\n",
            "change_key2:4\n",
            "comb_alpha:[0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1.]\n",
            "comb_beta_:[0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1.]\n",
            "self.comb_:[0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1.]\n",
            "contr_alpha:0.6856661274373337\n",
            "contr_beta:0.4718544908161928\n",
            "self.contr_norm:0.5346931596635712\n",
            "----------4\n",
            "rec_comb:[[0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "self.comb:[0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1.]\n",
            "change_key1:10\n",
            "change_key2:11\n",
            "comb_alpha:[0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1.]\n",
            "comb_beta_:[0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0.]\n",
            "self.comb_:[0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1.]\n",
            "contr_alpha:0.7670584651052388\n",
            "contr_beta:0.45597386276537627\n",
            "self.contr_norm:0.5346931596635712\n",
            "----------8\n",
            "rec_comb:[[0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1.]\n",
            " [0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1.]\n",
            " [0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0.]]\n",
            "self.comb:[0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1.]\n",
            "change_key1:15\n",
            "change_key2:15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-82d62438c548>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mmanager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m   \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mvar_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT_star\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_Mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-b3a06aa2a257>\u001b[0m in \u001b[0;36mlocal_search\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    114\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'change_key2:'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchange_key2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m       \u001b[0mcomb_alpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchange_key1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomb_alpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchange_key1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m       \u001b[0mcomb_beta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchange_key2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomb_alpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchange_key2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 15 is out of bounds for axis 0 with size 12"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULFlojoXWNyO"
      },
      "source": [
        "##実行ーmain\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUZyNh1JWNU1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "4c4c7276-0a64-4484-981c-cf1a1ef4879e"
      },
      "source": [
        "import numpy as np\r\n",
        "from os.path import expanduser  # new\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import csv\r\n",
        "from google.colab import drive\r\n",
        "import os\r\n",
        "import random\r\n",
        "\r\n",
        "N = 12  #要素数\r\n",
        "K = 3\r\n",
        "i = 1000  # 期数\r\n",
        "t = 100   #一期あたりの回数\r\n",
        "coord = 1\r\n",
        "file_specific = '_t_100_ver_' #ファイルにつける特異的な名前\r\n",
        "file_name ='/content/drive/My Drive'\r\n",
        "save_folder_name = '/NK_workshop/Graduation_ver/'\r\n",
        "\r\n",
        "KG_matrix = \\\r\n",
        "  np.array([\r\n",
        "            [2,5,6,7],\r\n",
        "            [3,3,4,5],\r\n",
        "            [4,2,3,4],\r\n",
        "            [6,1,2,3]\r\n",
        "            ])\r\n",
        "  \r\n",
        "Mt_arr = [2,3,4,6]\r\n",
        "counter = 1  \r\n",
        "result  = [[''] * t +2 for i in range(48)]\r\n",
        "\r\n",
        "for coord in range(3):\r\n",
        "\r\n",
        "  for Mt in Mt_arr:\r\n",
        "\r\n",
        "    for GG in [0,1,2,3]:\r\n",
        "\r\n",
        "      plt.figure(facecolor='white', figsize=(8, 6), dpi=150)\r\n",
        "\r\n",
        "      for KK in [1,2,3]:\r\n",
        "        G = KG_matrix[GG,0]\r\n",
        "        K = KG_matrix[GG,KK]\r\n",
        "        Kex = K - int(N/G) +1\r\n",
        "\r\n",
        "        print('G:'+ str(G))\r\n",
        "        print('K:'+ str(K))\r\n",
        "        print('Kex:'+ str(Kex)) \r\n",
        "        \r\n",
        "        NK_landscape = np.load(file_name + '/NK_workshop/NK_land_type_1' + '_D_' + str(G) + '_K_' + str(K) + '_i_' + str(i) + '.npy')\r\n",
        "\r\n",
        "        var_set = Var_set(N, K, Mt, coord) \r\n",
        "        environment = Environment(12, NK_landscape)\r\n",
        "        agent = Agent(var_set, environment)\r\n",
        "        rec_norm_all = np.zeros((i,t+1))\r\n",
        "\r\n",
        "        for i1 in range(i):\r\n",
        "          for t1 in range(t):\r\n",
        "            agent.local_search()\r\n",
        "          rec_norm_all[i1, 0:] = agent.rec_norm\r\n",
        "          agent = Agent(var_set, environment)\r\n",
        "          environment.step()\r\n",
        "          \r\n",
        "\r\n",
        "        rec_norm_all_average = []\r\n",
        "        for t2 in range(t):\r\n",
        "          rec_norm_all_average.append(np.sum(rec_norm_all[0:, t2]) / i)\r\n",
        "\r\n",
        "        result[counter-1][0] = str('_G_' + str(G) + '_K_' + str(K) + '_i_' + str(i)+'_Mt_'+str(var_set.Mt) + '_coord_' + str(var_set.coord))\r\n",
        "        result[counter-1][1:] = map(str,rec_norm_all_average)\r\n",
        "\r\n",
        "        x = range(t)\r\n",
        "        y = rec_norm_all_average\r\n",
        "\r\n",
        "        label_str = str('G='+str(G) +', K='+ str(K)+ ', Kex=' +str(Kex))\r\n",
        "        plt.plot(x,y, label = label_str)\r\n",
        "      plt.ylim(0,1)\r\n",
        "      if coord == 0:\r\n",
        "        coord_str = 'decentralized'\r\n",
        "      elif coord == 1:\r\n",
        "        coord_str = 'sequential'\r\n",
        "      elif coord == 2:\r\n",
        "        coord_str = 'proposal'\r\n",
        "      plt.title('Transition of normalized contribution ( Mt =' + str(var_set.Mt) + ', coord = ' + str(coord_str) + ')', size=12)\r\n",
        "      plt.xlabel('Time Periods', size=12)\r\n",
        "      plt.ylabel('Normalized contribution', size=12)\r\n",
        "      plt.legend(loc=4,prop={'size':10})\r\n",
        "      plt.legend(loc= 'best')\r\n",
        "      if not os.path.exists(file_name + save_folder_name):\r\n",
        "        os.makedirs(file_name + save_folder_name)\r\n",
        "      plt.savefig(file_name + save_folder_name+ '_G_' + str(G) + '_K_' + str(K) + '_i_' + str(i)+'_Mt_'+str(var_set.Mt) + '_coord_' + str(var_set.coord) +str(file_specific)+'.jpg', format='jpg')\r\n",
        "      print(str(counter) +  '周目が終わりました')\r\n",
        "      counter += 1\r\n",
        "\r\n",
        "      "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "G:2\n",
            "K:5\n",
            "Kex:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-65c8a6ac3937>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m           \u001b[0mrec_norm_all_average\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec_norm_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_G_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_K_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_i_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_Mt_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_coord_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrec_norm_all_average\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '_G_2_K_5_i_1000_Mt_2_coord_0'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x900 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfMgCKcJl_g-"
      },
      "source": [
        "###実行\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cuFh9cQKp-g"
      },
      "source": [
        "import numpy as np\n",
        "from os.path import expanduser  # new\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "from google.colab import drive\n",
        "import os\n",
        "import random\n",
        "\n",
        "N = 12  #要素数  \n",
        "i = 1000  # 期数\n",
        "t = 100   #一期あたりの回数\n",
        "D = 4   #部門数/ D=0のときcentralized\n",
        "P = int(N/D) #部門ごとの意思決定数\n",
        "file_specific = '_t_100_ver_' #ファイルにつける特異的な名前\n",
        "H = 1 #垂直的階層数(1-3)\n",
        "\n",
        "\n",
        "# *** 1. LOAD THE NK LANDSCAPE FILE *****************************************\n",
        "\n",
        "KD_matrix = \\\n",
        "  np.array([\n",
        "            [2,5,6,7],\n",
        "            [3,3,4,5],\n",
        "            [4,2,3,4],\n",
        "            [6,1,2,3]\n",
        "            ])\n",
        "\n",
        "D_array_original = select_divisor(N) #約数を格納するリスト\n",
        "Landscape_data = np.zeros((12,len(D_array_original)+6))\n",
        "\n",
        "\n",
        "# ***************************************************************************\n",
        "\n",
        "for DD in [0,1,2,3]:\n",
        "  for KK in [1,2,3]:\n",
        "    D = KD_matrix[DD,0]\n",
        "    K = KD_matrix[DD,KK]\n",
        "    D_original = D\n",
        "    P_original = int(N/D)\n",
        "\n",
        "    file_name ='/content/drive/My Drive'\n",
        "    NK_landscape = np.load(file_name + '/NK_workshop/NK_land_type_1'  + '_D_' + str(D) +\n",
        "                          '_K_' + str(K) + '_i_' + str(i) + '.npy')\n",
        "    \n",
        "\n",
        "\n",
        "    '''\n",
        "    以下で必要な準備\n",
        "\n",
        "    '''\n",
        "\n",
        "    D_prob_array = D_prob_make(D_array_original)\n",
        "\n",
        "    # *** 2. DECENTRALIZED LOCAL SEARCH *****************************************\n",
        "    Output3 = np.zeros((i, t))\n",
        "    for i1 in np.arange(i):\n",
        "        combination = np.random.binomial(1, 0.5, N)# 50%の確率の二項分布に従ったときの成功数をサンプル5つ分：N個の要素の配列/つまり、ランダムな1と0のN個の要素の配列\n",
        "        row = np.sum(combination*power_key)#10進数に直している\n",
        "        fitness = NK_landscape[i1, row, 2*N]#i1枚目のランドスケープのrow行2*N列を現在のfitnessとする\n",
        "        max_fit = np.max(NK_landscape[i1, :, 2*N])# use for normalization of perf\n",
        "        min_fit = np.min(NK_landscape[i1, :, 2*N])# ditto\n",
        "        fitness_norm = (fitness - min_fit)/(max_fit - min_fit)\n",
        "        #Dを入れる\n",
        "        #ロングジャンプ\n",
        "        if(0.9 < np.random.rand()):\n",
        "          D= np.random.choice(D_array_original)\n",
        "          \n",
        "        #prob_arrayの確率に従ってランダム選択\n",
        "        else:\n",
        "          D= np.random.choice(D_array_original, p = D_prob_array)     \n",
        "\n",
        "        for t1 in np.arange(t):\n",
        "            \n",
        "            Output3[i1, t1] = fitness_norm\n",
        "            row = np.sum(combination*power_key)\n",
        "\n",
        "            if D != 0:  #　部門別に行われるサーチ\n",
        "              if H <= 2: #階層数が2の場合\n",
        "                '''\n",
        "               ここに下でテストしているものが代入される\n",
        "                '''\n",
        "\n",
        "\n",
        "                combination = final_combs_D\n",
        "                row = int(np.sum(combination*power_key))\n",
        "                new_fitness = NK_landscape[i1, row, 2*N]  # 最終的な貢献 # final fitness\n",
        "                if new_fitness > fitness:\n",
        "                    fitness = new_fitness.copy()\n",
        "\n",
        "\n",
        "              if H = 1: #階層数が1の場合\n",
        "                 P = int(N/D) # 部門ごとの意思決定数\n",
        "                comb_D = np.hsplit(combination, D) # 組み合わせを部門ごとに分け、配列の形でそれぞれを保存\n",
        "                new_fits = np.zeros(P+1) #各貢献度を記録しておく配列\n",
        "                new_fits[P] = fitness #今の貢献度を代入する\n",
        "                final_combs_D = np.zeros(N) #最終結果を入れる配列を用意\n",
        "                for i2 in np.arange(D): \n",
        "                  s = int(i2*P)\n",
        "                  new_comb_D = comb_D[i2].copy() # 部門ごとの組み合わせを取得\n",
        "                  new_combs = np.zeros((D,P+1,N)) #組み合わせの全体を保存するための配列\n",
        "                  new_combs[i2,P,:] = combination.copy() #現在の組み合わせを保存する\n",
        "                # 以下、変更後の判定\n",
        "                  for i3 in np.arange(P):\n",
        "                    new_comb_D[i3]= abs(new_comb_D[i3] - 1) # 0→1、1→0へ/ abs()は絶対値を求める関数\n",
        "                    new_combs[i2,i3,:] = combination.copy() #元の組み合わせを代入\n",
        "                    new_combs[i2,i3,s:s+P] = new_comb_D #変えた組み合わせを代入\n",
        "                    row2 = int(np.sum(new_combs[i2,i3,:]*power_key))#変えた組み合わせを2進数に\n",
        "                    new_fits[i3] = NK_landscape[i1, row2, 2*N]  # 変更先の貢献度の平均\n",
        "                    new_comb_D = comb_D[i2].copy()\n",
        "                  final_combs_D[s:s+P] = new_combs[i2,np.argmax(new_fits),s:s+P]\n",
        "                combination = final_combs_D\n",
        "                row = int(np.sum(combination*power_key))\n",
        "                new_fitness = NK_landscape[i1, row, 2*N]  # 最終的な貢献 # final fitness\n",
        "                if new_fitness > fitness:\n",
        "                    fitness = new_fitness.copy()\n",
        "\n",
        "\n",
        "            elif D == 0:  # さもなければ、部門に分けない意思決定\n",
        "                new_combination = combination.copy()\n",
        "                choice_var = np.random.randint(N)\n",
        "                new_combination[choice_var] = abs(new_combination[choice_var] - 1)\n",
        "                row = np.sum(new_combination*power_key)\n",
        "                new_fitness = NK_landscape[i1, row, 2*N]\n",
        "                if new_fitness > fitness:\n",
        "                    combination = new_combination.copy()\n",
        "                    fitness = new_fitness.copy()\n",
        "            \n",
        "              \n",
        "        fitness_norm = (fitness - min_fit)/(max_fit - min_fit)\n",
        "\n",
        "        #normを記録する\n",
        "        D_norm_rec[i1+1, D_array_original.index(D)] = fitness_norm\n",
        "\n",
        "        #過去のnormの平均を計算し、累乗することで調整をかける\n",
        "        for i2 in np.arange(0, len(D_array_original), 1, dtype = int):\n",
        "          norm_ave[i2] = (np.sum(D_norm_rec[0:, i2])  / np.count_nonzero(D_norm_rec[0:, i2])) ** learn_strength\n",
        "\n",
        "\n",
        "        #調整後のnormの値をもとに、Dの選択確率を求める\n",
        "        for i3 in np.arange(0, len(D_array_original), 1, dtype = int):\n",
        "          D_prob_array[i3] = norm_ave[i3] / np.sum(norm_ave)\n",
        "          D_prob_rec[i1,i3] = D_prob_array[i3]\n",
        "\n",
        "        if final_max_fitness < fitness_norm:\n",
        "          final_max_fitness = fitness_norm\n",
        "\n",
        "    # *** 3. PLOT ***************************************************************\n",
        "\n",
        "    # plt.figure(1,facecolor='white', figsize=(8, 6), dpi=75)  # for screens with\n",
        "    # # higher resolution change dpi to 150 or 200. For normal use 75.\n",
        "    # plt.ylim(0, 1)\n",
        "    # plt.xlim(1,1000)\n",
        "    # plt.legend(loc=4,prop={'size':10})\n",
        "    # plt.title('Results of local search', size=12)\n",
        "    # plt.xlabel('time periods', size=12)\n",
        "    # plt.ylabel('fitness', size=12)\n",
        "\n",
        "    ave_norm = np.sum(D_norm_rec) / 1000\n",
        "\n",
        "    Landscape_data[count_cycle,0] = D_original\n",
        "    Landscape_data[count_cycle,1] = K\n",
        "    Landscape_data[count_cycle,2] = K-P_original+1\n",
        "    Landscape_data[count_cycle,3] = final_max_fitness\n",
        "    Landscape_data[count_cycle,4] = ave_norm\n",
        "    Landscape_data[count_cycle,5] = D_array_original[np.argmax(D_prob_array)]\n",
        "    count_figure = 6\n",
        "    for iii3 in range(len(D_array_original)):\n",
        "      Landscape_data[count_cycle, count_figure] = D_prob_array[iii3]\n",
        "      count_figure += 1\n",
        "\n",
        "    count_cycle += 1\n",
        "\n",
        "    print('LandscapeのD:' + str(D_original))\n",
        "    print('Kの値：' + str(K))\n",
        "    print('最大のNorm:'+str(final_max_fitness))\n",
        "    print('normの平均：'+str(ave_norm))\n",
        "    print('--Dの選択確率------')\n",
        "    for iii2 in range(len(D_array_original)):\n",
        "      print('D=' + str(D_array_original[iii2])+ 'の選択確率：' + str(D_prob_array[iii2])) \n",
        "    print('Dの選択確率が最大の際のＤ：'+ str(D_array_original[np.argmax(D_prob_array)]))\n",
        "    print('--*****************************************-----')\n",
        "\n",
        "    plt.figure(facecolor='white', figsize=(8, 6), dpi=150)  # for screens with\n",
        "    # higher resolution change dpi to 150 or 200. For normal use 75.\n",
        "    for iii4 in range(len(D_array_original)):\n",
        "      if iii4 == 0:\n",
        "        plt.plot(D_prob_rec[0:,iii4], label = 'cen')\n",
        "      else:\n",
        "       plt.plot(D_prob_rec[0:,iii4], label = str(D_array_original[iii4]))\n",
        "    plt.ylim(0, 0.7)\n",
        "    plt.xlim(0,1000)\n",
        "    plt.legend(loc=4,prop={'size':10})\n",
        "    plt.title('Transition of selection probability of Mt (G='+str(D_original) +', K='+ str(K)+ ', Kex=' +str(K-P_original+1)+')', size=12)\n",
        "    plt.xlabel('Time Periods', size=12)\n",
        "    plt.ylabel('Selection Probability of Mt', size=12)\n",
        "    plt.legend(loc='upper left', bbox_to_anchor=(1,1))\n",
        "    plt.savefig(file_name + '/NK_workshop/_D_' + str(D_original) +\n",
        "                          '_K_' + str(K) + '_i_' + str(i)+'_'+str(file_specific)+'.jpg', format='jpg')\n",
        "    if not os.path.exists(file_name + '/NK_workshop/'):\n",
        "      os.makedirs(file_name + '/NK_workshop/')\n",
        "    np.savetxt(file_name + '/NK_workshop/_D_'+str(D)+'_Kex_'+str(K-P_original+1)+'_norm_rec_'+str(file_specific)+'.csv',D_norm_rec,delimiter=',')\n",
        "    print(file_name + '/NK_workshop/result_for_figure'+str(file_specific)+'.csv')\n",
        "    \n",
        "\n",
        "\n",
        "if not os.path.exists(file_name + '/NK_workshop/'):\n",
        "    os.makedirs(file_name + '/NK_workshop/')\n",
        "np.savetxt(file_name + '/NK_workshop/result_for_figure'+str(file_specific)+'.csv',Landscape_data,delimiter=',')\n",
        "print(file_name + '/NK_workshop/result_for_figure'+str(file_specific)+'.csv')\n",
        "\n",
        "    # END OF LINE\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}